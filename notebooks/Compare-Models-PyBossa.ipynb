{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import display, HTML, Markdown\n",
    "import datetime\n",
    "import pytz\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "import vessel_scoring.models\n",
    "import vessel_scoring.evaluate_model\n",
    "from vessel_scoring import utils\n",
    "import vessel_scoring.data\n",
    "from glob import glob\n",
    "import os\n",
    "from vessel_scoring import data, utils\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "\n",
    "\n",
    "sys.path.append(\"../../training-data-source\")\n",
    "import tools as trtools\n",
    "sys.path.append(\"../../vessel-classification-pipeline/classification\")\n",
    "from  classification.utility import is_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data. \n",
    "# ==============\n",
    "\n",
    "# Load training and test data\n",
    "\n",
    "def load_data(*names, **kw):\n",
    "    res = []\n",
    "    for name in names:\n",
    "        d = np.load('../../datasets/data/labeled/%s.measures.labels.npz' % name)['x']\n",
    "        d = append_fields(d, 'classification', d['is_fishing'])\n",
    "        d = d[~(np.isinf(d['classification']) | np.isnan(d['classification']) | \n",
    "                np.isnan(d['timestamp']) | np.isnan(d['speed']) & np.isnan(d['course']))]\n",
    "        if len(d):\n",
    "            res.append(d)\n",
    "    return np.concatenate(res)\n",
    "\n",
    "all_lline = load_data(\"pybossa_project_3_Drifting_longlines\")\n",
    "all_trawl = load_data(\"pybossa_project_3_Trawlers\")\n",
    "all_pseine = load_data(\"pybossa_project_3_Purse_seines\")\n",
    "\n",
    "# Slow transits (used to train models to avoid classifying slow transits as fishing)\n",
    "all_tran = load_data(\n",
    "    \"false_positives_Drifting_longlines\",\n",
    "    \"false_positives_Fixed_gear\",\n",
    "    \"false_positives_Purse_seines\",\n",
    "    \"false_positives_Trawlers\",\n",
    "    \"false_positives_Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rngdata = {\n",
    "    'longliner' : np.concatenate([all_lline, all_tran]),\n",
    "    'trawler' : np.concatenate([all_trawl, all_tran]),\n",
    "    'ps' : np.concatenate([all_pseine, all_tran])\n",
    "}\n",
    "\n",
    "tran_mmsi = set(all_tran['mmsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then load mappings MMSI to true / inferred gear type\n",
    "\n",
    "def gear_name_of(x):\n",
    "    return x        \n",
    "        \n",
    "# Create datasets for training and testing\n",
    "\n",
    "def is_test_id(x):\n",
    "    # TODO: use list of MMSI from somewhere to \n",
    "    # \n",
    "    return is_test(int(x))\n",
    "\n",
    "\n",
    "all_data = np.concatenate([x for x in rngdata.values()])\n",
    "\n",
    "all_data['is_fishing'] = (all_data['is_fishing'] > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = {}\n",
    "train_data = {}\n",
    "np.random.seed(4321)\n",
    "for gear_type in sorted(rngdata):    \n",
    "    available_mmsi = sorted(set(rngdata[gear_type]['mmsi']) - tran_mmsi)\n",
    "    np.random.shuffle(available_mmsi)\n",
    "    n = len(available_mmsi) // 2\n",
    "    # use the true gear types for the training data\n",
    "    train_mmsi = set(available_mmsi[:n]) | tran_mmsi\n",
    "    true_mask = [(x in train_mmsi) for x in rngdata[gear_type]['mmsi']]\n",
    "    true_mask = np.array(true_mask, dtype=bool)\n",
    "    if true_mask.sum():\n",
    "        train_data[gear_type] = rngdata[gear_type][true_mask]    \n",
    "\n",
    "    test_mmsi = set(available_mmsi[n:])\n",
    "    test_mask = [(x in test_mmsi) for x in rngdata[gear_type]['mmsi']]\n",
    "    test_mask = np.array(test_mask, dtype=bool)\n",
    "    if test_mask.sum():\n",
    "        test_data[gear_type] = rngdata[gear_type][test_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longliner 98 9 10\n",
      "ps 96 7 8\n",
      "trawler 104 15 15\n"
     ]
    }
   ],
   "source": [
    "for gear_type in sorted(rngdata):\n",
    "    total_train = len(set(train_data[gear_type]['mmsi']))\n",
    "    print(gear_type, total_train, len(set(train_data[gear_type]['mmsi'])) - len(tran_mmsi), len(set(test_data[gear_type]['mmsi'])))\n",
    "    assert not set(train_data[gear_type]['mmsi']) & set(test_data[gear_type]['mmsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_fishing_localization(true_ranges, inferred_ranges):\n",
    "\n",
    "    all_mmsi = sorted(set(x.mmsi for x in true_ranges))\n",
    "\n",
    "    true_by_mmsi = {}\n",
    "    pred_by_mmsi = {}\n",
    "\n",
    "    for mmsi in all_mmsi:\n",
    "        true = np.array([x for x in true_ranges if x.mmsi == mmsi])\n",
    "        inferred = np.array([x for x in inferred_ranges if x.mmsi == mmsi])\n",
    "\n",
    "        # Determine minutes from start to finish of this mmsi, create an array to\n",
    "        # hold results and fill with -1 (unknown)\n",
    "        _, start, end, _ = true[0]\n",
    "        for (_, s, e, _) in true[1:]:\n",
    "            start = min(start, s)\n",
    "            end = max(end, e)\n",
    "        start_min = datetime_to_minute(start)\n",
    "        end_min = datetime_to_minute(end)\n",
    "        \n",
    "        minutes = np.empty([end_min - start_min + 1, 2], dtype=int)\n",
    "        minutes.fill(-1)\n",
    "\n",
    "        # Fill in minutes[:, 0] with known true / false values\n",
    "        for (_, s, e, is_fishing) in true:\n",
    "            s_min = datetime_to_minute(s)\n",
    "            e_min = datetime_to_minute(e)\n",
    "            for m in range(s_min - start_min, e_min - start_min + 1):\n",
    "                minutes[m, 0] = is_fishing\n",
    "\n",
    "        # fill in minutes[:, 1] with in inferred values\n",
    "        for (_, s, e, is_fishing) in inferred:\n",
    "            s_min = datetime_to_minute(s)\n",
    "            e_min = datetime_to_minute(e)\n",
    "            for m in range(s_min - start_min, e_min - start_min + 1):\n",
    "                if 0 <= m < len(minutes):\n",
    "                    minutes[m, 1] = is_fishing       \n",
    " \n",
    "        mask = ((minutes[:, 0] != -1) & (minutes[:, 1] != -1))\n",
    "\n",
    "        if mask.sum():\n",
    "            true_by_mmsi[mmsi] = minutes[mask, 0]\n",
    "            pred_by_mmsi[mmsi] = minutes[mask, 1]\n",
    "            \n",
    "    return true_by_mmsi, pred_by_mmsi\n",
    "\n",
    "def ranges_from_ais(ais, is_fishing):\n",
    "    points = [trtools.Point(x['mmsi'], \n",
    "                            datetime.datetime.utcfromtimestamp(x['timestamp']).replace(tzinfo=pytz.utc), is_fishing[i])\n",
    "              for i, x in enumerate(ais)]\n",
    "    return trtools.ranges_from_points(points)\n",
    "\n",
    "def datetime_to_minute(dt):\n",
    "    timestamp = (dt - datetime.datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()\n",
    "    return int(timestamp // 60)\n",
    "\n",
    "def model_true_inferred(mdl, test_data):\n",
    "    check =  mdl.predict_proba(test_data)[:,1]\n",
    "    \n",
    "    inferred_ranges = list(ranges_from_ais(test_data, mdl.predict_proba(test_data)[:,1] > 0.5))\n",
    "    true_ranges = list(ranges_from_ais(test_data, test_data['is_fishing'] > 0.5))\n",
    "    \n",
    "    true, inferred = compare_fishing_localization(true_ranges, inferred_ranges)\n",
    "    \n",
    "    y_true = np.concatenate(true.values())\n",
    "    y_pred = np.concatenate(inferred.values())\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "def model_metrics(y_true, y_pred):\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, accuracy, f1, y_true, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Random Forest with Distances</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|Model|Train MMSI|Train Pts|Test MMSI|Test Pts|Precision|Recall|Accuracy|F1-Score|True-Ratio|\n",
       "|-----|----------|---------|---------|--------|---------|------|--------|--------|----------|\n",
       "|longliner|9|108662|10|270174|0.96|0.64|0.82|0.77|0.46|\n",
       "|ps|7|20344|8|117626|0.82|0.54|0.84|0.65|0.28|\n",
       "|trawler|15|145458|15|510027|0.98|0.97|0.99|0.98|0.32|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Logistic</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|Model|Train MMSI|Train Pts|Test MMSI|Test Pts|Precision|Recall|Accuracy|F1-Score|True-Ratio|\n",
       "|-----|----------|---------|---------|--------|---------|------|--------|--------|----------|\n",
       "|longliner|9|108662|10|266893|0.90|0.89|0.90|0.89|0.46|\n",
       "|ps|7|20344|8|117203|0.90|0.23|0.78|0.37|0.28|\n",
       "|trawler|15|145458|15|508505|0.96|0.96|0.97|0.96|0.32|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "        ('Random Forest with Distances', vessel_scoring.random_forest_model.RandomForestModel(\n",
    "                colspec=dict(windows=vessel_scoring.colspec.Colspec.windows,\n",
    "                                measures=['speed', 'distance_from_shore', 'distance_from_port']))),\n",
    "        ('Logistic', vessel_scoring.logistic_model.LogisticModel(order=6,\n",
    "                colspec=dict(windows=vessel_scoring.colspec.Colspec.windows,\n",
    "                                measures=['measure_speed']))),\n",
    "] \n",
    "\n",
    "for name, mdl in models:\n",
    "\n",
    "    lines = [\"|Model|Train MMSI|Train Pts|Test MMSI|Test Pts|Precision|Recall|Accuracy|F1-Score|True-Ratio|\",\n",
    "             \"|-----|----------|---------|---------|--------|---------|------|--------|--------|----------|\"]\n",
    "\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_mmsi = []\n",
    "\n",
    "    for gear in sorted(rngdata):\n",
    "                \n",
    "        title = gear\n",
    "\n",
    "        gear_name = gear #os.path.splitext(os.path.splitext(gear)[0])[0][9:]\n",
    "\n",
    "        print(\".\", end=\"\")\n",
    "        \n",
    "        if gear not in test_data:\n",
    "            continue\n",
    "        \n",
    "        trained = vessel_scoring.models.train_model_on_data(mdl, train_data[gear])\n",
    "        \n",
    "        y_true, y_pred =  model_true_inferred(trained, test_data[gear])\n",
    "        \n",
    "\n",
    "        mmsi = test_data[gear]['mmsi'].astype(int)\n",
    "        all_mmsi.append(mmsi)\n",
    "                \n",
    "        all_true.append(y_true)\n",
    "        all_pred.append(y_pred)\n",
    "\n",
    "        train_mmsi = set(train_data[gear]['mmsi']) - tran_mmsi\n",
    "        train_pts = sum([(train_data[gear]['mmsi'] == m).sum() for m in train_mmsi])\n",
    "        #\n",
    "        mmsi_count = len(set(mmsi))\n",
    "        n_points = len(y_true)\n",
    "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "        precision = metrics.precision_score(y_true, y_pred)\n",
    "        recall = metrics.recall_score(y_true, y_pred)\n",
    "        f1 = metrics.f1_score(y_true, y_pred)\n",
    "        ratio = y_true.sum() / len(y_true)\n",
    "        # Add to Markdown table\n",
    "        lines.append('|{}|{}|{}|{}|{}|'.format(gear, len(train_mmsi), train_pts, mmsi_count, n_points) + '|'.join(['{:.2f}'.format(x) for x in\n",
    "                                    [precision, recall, accuracy, f1, ratio]]) + '|')\n",
    " \n",
    "    display(HTML(\"<h2>{}</h2>\".format(name)))\n",
    "\n",
    "    display(Markdown('\\n'.join(lines)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transit MMSI: 89\n",
      "Transit Points: 19728\n"
     ]
    }
   ],
   "source": [
    "# Note that the training counts excludes the transits, which are included in the training set as well\n",
    "print(\"Transit MMSI:\", len(tran_mmsi))\n",
    "print(\"Transit Points:\", sum([(train_data[gear]['mmsi'] == m).sum() for m in tran_mmsi]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
